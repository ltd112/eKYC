{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Nam_5\\KLTN\\e-kyc\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import torch\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract face using MTCNN\n",
    "def extract_face(img: np.ndarray, model: MTCNN, padding=None, min_prob=0.9):\n",
    "    boxes, prob, landmarks = model.detect(img, landmarks=True)\n",
    "\n",
    "    if boxes is not None:\n",
    "        boxes = boxes[prob > min_prob]\n",
    "\n",
    "        max_area = 0\n",
    "        max_box = [0, 0, 0, 0]\n",
    "        max_landmarks = []\n",
    "\n",
    "        for i, box in enumerate(boxes):\n",
    "            box = np.clip(box, 0, np.inf).astype(np.uint32)\n",
    "            x1, y1, x2, y2 = box\n",
    "            if (x2 - x1) * (y2 - y1) > max_area:\n",
    "                max_box = padding_face(box, padding)\n",
    "                max_area = (x2 - x1) * (y2 - y1)\n",
    "                max_landmarks = landmarks[i]\n",
    "\n",
    "        x1, y1, x2, y2 = max_box\n",
    "        face = img[y1: y2, x1: x2, ...]\n",
    "\n",
    "        return face, max_box, max_landmarks\n",
    "    else:\n",
    "        return img, None, None\n",
    "\n",
    "# Padding function for bounding box\n",
    "def padding_face(box: np.ndarray, padding=None):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cx = (x1 + x2) // 2\n",
    "    cy = (y1 + y2) // 2\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    if padding:\n",
    "        if isinstance(padding, float):\n",
    "            w = w * padding\n",
    "            h = h * padding\n",
    "        else:\n",
    "            w = w + padding\n",
    "            h = h + padding\n",
    "\n",
    "    x1 = cx - w // 2\n",
    "    x2 = cx + w // 2\n",
    "    y1 = cy - h // 2\n",
    "    y2 = cy + h // 2\n",
    "\n",
    "    box = np.clip([x1, y1, x2, y2], 0, np.inf).astype(np.uint32)\n",
    "    return box\n",
    "\n",
    "# Helper function to load images\n",
    "def get_image(filename):\n",
    "    img = cv.imread(filename)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "# Function to verify two images using DeepFace.verify()\n",
    "def verify(img1: np.ndarray, img2: np.ndarray, detector_model: MTCNN):\n",
    "    # Step 1: Extract faces using MTCNN\n",
    "    face1, _, _ = extract_face(img1, detector_model)\n",
    "    face2, _, _ = extract_face(img2, detector_model)\n",
    "\n",
    "    # Step 2: Save the cropped faces to the 'crop' folder\n",
    "    save_path1 = \"crop/face1.jpg\"\n",
    "    save_path2 = \"crop/face2.jpg\"\n",
    "    save_cropped_face(face1, save_path1)\n",
    "    save_cropped_face(face2, save_path2)\n",
    "\n",
    "    # Step 3: Use DeepFace to verify the faces\n",
    "    result = DeepFace.verify(\n",
    "        img1_path=save_path1,\n",
    "        img2_path=save_path2,\n",
    "        model_name=\"Facenet\",  # Can be changed to other models like VGG-Face, OpenFace, etc.\n",
    "        enforce_detection=False,  # Since we're using MTCNN, no need to enforce detection here\n",
    "        distance_metric=\"cosine\"  # Or other metrics like \"euclidean\", \"L1\"\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cropped face to a folder named 'crop'\n",
    "def save_cropped_face(face: np.ndarray, save_path: str):\n",
    "    if not os.path.exists('crop'):\n",
    "        os.makedirs('crop')  # Create 'crop' directory if it doesn't exist\n",
    "    cv.imwrite(save_path, cv.cvtColor(face, cv.COLOR_RGB2BGR))  # Save the image in BGR format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verified': True, 'distance': 0.2420265020039819, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 39, 'w': 777, 'h': 954, 'left_eye': (569, 418), 'right_eye': (238, 414)}}, 'time': 2.08}\n"
     ]
    }
   ],
   "source": [
    "# Loading images using OpenCV\n",
    "filename1 = \"./file_test/ccDat.jpg\"\n",
    "filename2 = \"./file_test/datv2.jpg\"\n",
    "image1 = get_image(filename1)\n",
    "image2 = get_image(filename2)\n",
    "\n",
    "# Device setup for MTCNN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "detector_model = MTCNN(device=device)\n",
    "\n",
    "# Verifying the images using DeepFace\n",
    "results = verify(image1, image2, detector_model)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to verify an image against a real-time frame\n",
    "def verify_with_camera(img1: np.ndarray, detector_model: MTCNN):\n",
    "    cap = cv.VideoCapture(0)  # Open webcam\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot access the webcam.\")\n",
    "        return\n",
    "\n",
    "    print(\"Press 'q' to quit.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read from the webcam.\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB\n",
    "        frame_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        # Extract face from the webcam frame\n",
    "        face_cam, _, _ = extract_face(frame_rgb, detector_model)\n",
    "\n",
    "        if face_cam is not None:\n",
    "            # Save the webcam face to 'crop' folder\n",
    "            save_path_cam = \"crop/face_cam.jpg\"\n",
    "            save_cropped_face(face_cam, save_path_cam)\n",
    "\n",
    "            # Verify the first image against the webcam face\n",
    "            result = DeepFace.verify(\n",
    "                img1_path=\"crop/face1.jpg\",  # Pre-cropped first image\n",
    "                img2_path=save_path_cam,\n",
    "                model_name=\"Facenet\",\n",
    "                enforce_detection=False,\n",
    "                distance_metric=\"cosine\"\n",
    "            )\n",
    "\n",
    "            print(result)  # Display the verification result\n",
    "\n",
    "        # Display the webcam feed\n",
    "        cv.imshow(\"Webcam\", frame)\n",
    "\n",
    "        # Exit the loop when 'q' is pressed\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit.\n",
      "{'verified': False, 'distance': 0.4274185999408249, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 177, 'h': 227, 'left_eye': None, 'right_eye': None}}, 'time': 1.19}\n",
      "{'verified': False, 'distance': 0.44778536765056665, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 173, 'h': 217, 'left_eye': None, 'right_eye': None}}, 'time': 1.42}\n",
      "{'verified': False, 'distance': 0.40046587495467745, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 181, 'h': 223, 'left_eye': None, 'right_eye': None}}, 'time': 1.13}\n",
      "{'verified': False, 'distance': 0.45413219857575315, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 177, 'h': 223, 'left_eye': None, 'right_eye': None}}, 'time': 1.14}\n",
      "{'verified': False, 'distance': 0.4678575820818134, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 169, 'h': 207, 'left_eye': None, 'right_eye': None}}, 'time': 1.19}\n",
      "{'verified': False, 'distance': 0.5046395674847175, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 183, 'h': 215, 'left_eye': None, 'right_eye': None}}, 'time': 1.08}\n",
      "{'verified': False, 'distance': 0.43124922923501197, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 175, 'h': 211, 'left_eye': None, 'right_eye': None}}, 'time': 1.14}\n",
      "{'verified': False, 'distance': 0.4109031722685963, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 181, 'h': 223, 'left_eye': None, 'right_eye': None}}, 'time': 1.0}\n",
      "{'verified': False, 'distance': 0.44969426118069555, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 219, 'h': 265, 'left_eye': (162, 104), 'right_eye': (57, 115)}}, 'time': 1.2}\n",
      "{'verified': False, 'distance': 0.4302392576965265, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 207, 'h': 262, 'left_eye': None, 'right_eye': None}}, 'time': 0.97}\n",
      "{'verified': False, 'distance': 0.400879136071993, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 209, 'h': 251, 'left_eye': None, 'right_eye': None}}, 'time': 1.32}\n",
      "{'verified': False, 'distance': 0.41028994573661404, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 201, 'h': 247, 'left_eye': (148, 93), 'right_eye': (52, 101)}}, 'time': 1.17}\n",
      "{'verified': False, 'distance': 0.4543092975652755, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 193, 'h': 243, 'left_eye': (150, 88), 'right_eye': (56, 98)}}, 'time': 1.11}\n",
      "{'verified': False, 'distance': 0.49636560961168996, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 203, 'h': 237, 'left_eye': None, 'right_eye': None}}, 'time': 1.05}\n",
      "{'verified': False, 'distance': 0.44496837913449705, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 195, 'h': 227, 'left_eye': None, 'right_eye': None}}, 'time': 1.07}\n",
      "{'verified': True, 'distance': 0.39971772292998664, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 181, 'h': 235, 'left_eye': (143, 93), 'right_eye': (53, 95)}}, 'time': 1.11}\n",
      "{'verified': True, 'distance': 0.394770662702025, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 173, 'h': 227, 'left_eye': None, 'right_eye': None}}, 'time': 1.06}\n",
      "{'verified': True, 'distance': 0.39334032461572366, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 183, 'h': 232, 'left_eye': None, 'right_eye': None}}, 'time': 1.1}\n",
      "{'verified': True, 'distance': 0.3876975611755884, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 3, 'w': 181, 'h': 227, 'left_eye': None, 'right_eye': None}}, 'time': 1.05}\n",
      "{'verified': True, 'distance': 0.36531014211372037, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 181, 'h': 230, 'left_eye': None, 'right_eye': None}}, 'time': 1.0}\n",
      "{'verified': False, 'distance': 0.40238422719746847, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 181, 'h': 235, 'left_eye': None, 'right_eye': None}}, 'time': 0.95}\n",
      "{'verified': False, 'distance': 0.4188428338932174, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 4, 'w': 183, 'h': 223, 'left_eye': None, 'right_eye': None}}, 'time': 1.0}\n",
      "{'verified': True, 'distance': 0.36598542802995904, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 1, 'w': 179, 'h': 220, 'left_eye': None, 'right_eye': None}}, 'time': 0.99}\n",
      "{'verified': False, 'distance': 0.43009431793942543, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 181, 'h': 226, 'left_eye': None, 'right_eye': None}}, 'time': 1.13}\n",
      "{'verified': False, 'distance': 0.423436712304212, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 189, 'h': 235, 'left_eye': None, 'right_eye': None}}, 'time': 2.29}\n",
      "{'verified': False, 'distance': 0.4238321169070195, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 175, 'h': 221, 'left_eye': None, 'right_eye': None}}, 'time': 1.56}\n",
      "{'verified': True, 'distance': 0.3992295003361114, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 177, 'h': 229, 'left_eye': None, 'right_eye': None}}, 'time': 1.12}\n",
      "{'verified': False, 'distance': 0.4871928205007432, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 175, 'h': 217, 'left_eye': None, 'right_eye': None}}, 'time': 1.32}\n",
      "{'verified': False, 'distance': 0.5410423586728984, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 185, 'h': 227, 'left_eye': None, 'right_eye': None}}, 'time': 1.28}\n",
      "{'verified': False, 'distance': 0.44632526617582235, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 175, 'h': 219, 'left_eye': None, 'right_eye': None}}, 'time': 1.29}\n",
      "{'verified': False, 'distance': 0.4227505744505927, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 179, 'h': 235, 'left_eye': None, 'right_eye': None}}, 'time': 1.0}\n",
      "{'verified': True, 'distance': 0.32462850957045397, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 177, 'h': 231, 'left_eye': None, 'right_eye': None}}, 'time': 1.08}\n",
      "{'verified': False, 'distance': 0.43991632859884466, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 179, 'h': 235, 'left_eye': None, 'right_eye': None}}, 'time': 1.17}\n",
      "{'verified': False, 'distance': 0.41932552043003357, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 183, 'h': 235, 'left_eye': None, 'right_eye': None}}, 'time': 1.1}\n",
      "{'verified': False, 'distance': 0.43055768692663854, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 179, 'h': 229, 'left_eye': None, 'right_eye': None}}, 'time': 1.19}\n",
      "{'verified': False, 'distance': 0.41579097790858854, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 185, 'h': 235, 'left_eye': None, 'right_eye': None}}, 'time': 1.16}\n",
      "{'verified': False, 'distance': 0.4562353966595166, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 185, 'h': 232, 'left_eye': None, 'right_eye': None}}, 'time': 1.29}\n",
      "{'verified': False, 'distance': 0.4304353940320286, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 193, 'h': 217, 'left_eye': None, 'right_eye': None}}, 'time': 1.53}\n",
      "{'verified': True, 'distance': 0.38452871148092904, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 4, 'w': 183, 'h': 228, 'left_eye': None, 'right_eye': None}}, 'time': 1.56}\n",
      "{'verified': False, 'distance': 0.40311093728060954, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 177, 'h': 225, 'left_eye': None, 'right_eye': None}}, 'time': 1.36}\n",
      "{'verified': True, 'distance': 0.36285017174957235, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 185, 'h': 237, 'left_eye': None, 'right_eye': None}}, 'time': 1.33}\n",
      "{'verified': False, 'distance': 0.4901151082732912, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 183, 'h': 235, 'left_eye': None, 'right_eye': None}}, 'time': 1.24}\n",
      "{'verified': False, 'distance': 0.4665334453752419, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 173, 'h': 213, 'left_eye': None, 'right_eye': None}}, 'time': 1.4}\n",
      "{'verified': False, 'distance': 0.41076839181134317, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 183, 'h': 231, 'left_eye': None, 'right_eye': None}}, 'time': 1.31}\n",
      "{'verified': False, 'distance': 0.4911150203532034, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 171, 'h': 225, 'left_eye': None, 'right_eye': None}}, 'time': 1.25}\n",
      "{'verified': False, 'distance': 0.49279975538539833, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 179, 'h': 227, 'left_eye': None, 'right_eye': None}}, 'time': 1.18}\n",
      "{'verified': False, 'distance': 0.4358273458759866, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 181, 'h': 227, 'left_eye': (132, 84), 'right_eye': (50, 88)}}, 'time': 1.09}\n",
      "{'verified': False, 'distance': 0.4848823249603328, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 177, 'h': 221, 'left_eye': None, 'right_eye': None}}, 'time': 1.06}\n",
      "{'verified': False, 'distance': 0.4899754986079893, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 175, 'h': 215, 'left_eye': None, 'right_eye': None}}, 'time': 1.09}\n",
      "{'verified': False, 'distance': 0.5049619847986504, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 181, 'h': 223, 'left_eye': None, 'right_eye': None}}, 'time': 1.13}\n",
      "{'verified': False, 'distance': 0.4649105637400316, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 177, 'h': 223, 'left_eye': None, 'right_eye': None}}, 'time': 1.08}\n",
      "{'verified': True, 'distance': 0.38356666404412754, 'threshold': 0.4, 'model': 'Facenet', 'detector_backend': 'opencv', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 23, 'w': 361, 'h': 422, 'left_eye': (278, 183), 'right_eye': (113, 190)}, 'img2': {'x': 0, 'y': 0, 'w': 179, 'h': 224, 'left_eye': (134, 85), 'right_eye': (49, 89)}}, 'time': 1.06}\n"
     ]
    }
   ],
   "source": [
    "# Loading the first image\n",
    "filename1 = \"./file_test/ccDat.jpg\"\n",
    "image1 = get_image(filename1)\n",
    "\n",
    "# Device setup for MTCNN\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "detector_model = MTCNN(device=device)\n",
    "\n",
    "# Extract and save the face from the first image\n",
    "face1, _, _ = extract_face(image1, detector_model)\n",
    "if face1 is not None:\n",
    "    save_cropped_face(face1, \"crop/face1.jpg\")\n",
    "else:\n",
    "    print(\"Error: No face detected in the first image.\")\n",
    "    exit()\n",
    "\n",
    "# Start real-time verification\n",
    "verify_with_camera(image1, detector_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
